from openai import OpenAI
import os
import json
from datetime import datetime, timedelta

# LM Studio local server configuration
LM_STUDIO_BASE_URL = "http://127.0.0.1:1234"  # LM Studio'nun varsayÄ±lan portu
#MODEL_NAME = "openai/gpt-oss-20b"  # LM Studio'da yÃ¼klediÄŸiniz model adÄ±
MODEL_NAME = "qwen/qwen3-4b-2507"

TRANSCRIPT_INPUT_FILE = "TanÄ±nan Metin.txt"
ACTION_ITEMS_OUTPUT_FILE = "eylem_maddeleri.txt"
ACTION_ITEMS_JSON_FILE = "eylem_maddeleri.json"
MEETING_SUMMARY_FILE = "toplanti_ozeti.txt"

# LM Studio client'Ä±nÄ± yapÄ±landÄ±r
client = OpenAI(
    base_url=LM_STUDIO_BASE_URL + "/v1",
    api_key="lm-studio"  # LM Studio iÃ§in dummy key
)

def get_action_items_with_lm_studio(transcript_text):
    if not transcript_text.strip() or transcript_text == "Metin bulunamadÄ±":
        return "Transkript metni boÅŸ veya bulunamadÄ±, aksiyon maddeleri Ã§Ä±karÄ±lamadÄ±."

    prompt = f"""
AÅŸaÄŸÄ±daki toplantÄ± transkriptini analiz et ve toplantÄ±da geÃ§en tÃ¼m uygulanabilir gÃ¶rev/aksiyon maddelerini Ã§Ä±kar. 
- GÃ¶revler net, aÃ§Ä±k ve uygulanabilir olmalÄ±.
- TÃ¼m mantÄ±klÄ± gÃ¶revleri dahil et, hiÃ§bir aÃ§Ä±kÃ§a belirtilen gÃ¶revi atlama.
- Genel konuÅŸmalarÄ± ve tekrarlarÄ± dahil etme.

Format:
* **GÃ¶revi:** GÃ¶rev aÃ§Ä±klamasÄ±
    * **KiÅŸi:** Ä°lgili kiÅŸi adÄ± (varsa, belirtilmemiÅŸ ise "belirtilmemiÅŸ")
    * **Son Tarih:** gg.aa.yyyy veya belirtilmemiÅŸ

Transkript:
{transcript_text}

GÃ¶rev ve Aksiyon Maddeleri:
"""

    print("\nLM Studio'ya aksiyon maddeleri Ã§Ä±karma isteÄŸi gÃ¶nderiliyor...")
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": "Sen bir toplantÄ± analiz uzmanÄ±sÄ±n. ToplantÄ± transkriptlerinden aksiyon maddelerini Ã§Ä±karma konusunda uzmansÄ±n."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=2000
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"LM Studio'dan yanÄ±t alÄ±nÄ±rken hata oluÅŸtu: {e}")
        print("LM Studio'nun Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan ve modelin yÃ¼klendiÄŸinden emin olun.")
        return "GÃ¶rev maddeleri Ã§Ä±karÄ±lamadÄ±."

def get_meeting_summary_with_lm_studio(transcript_text):
    if not transcript_text.strip() or transcript_text == "Metin bulunamadÄ±":
        return "Transkript metni boÅŸ veya bulunamadÄ±, toplantÄ± Ã¶zeti Ã§Ä±karÄ±lamadÄ±."

    prompt = f"""
AÅŸaÄŸÄ±daki toplantÄ± transkriptini analiz et ve kapsamlÄ± bir toplantÄ± Ã¶zeti Ã§Ä±kar.

Ã–zet ÅŸu bÃ¶lÃ¼mleri iÃ§ermeli:
1. **ToplantÄ± Konusu:** Ana konu ve amaÃ§
2. **KatÄ±lÄ±mcÄ±lar:** ToplantÄ±ya katÄ±lan kiÅŸiler
3. **Ana Konular:** TartÄ±ÅŸÄ±lan baÅŸlÄ±ca konular
4. **Kararlar:** AlÄ±nan kararlar ve sonuÃ§lar
5. **Ã–nemli Noktalar:** Vurgulanan Ã¶nemli bilgiler
6. **Sonraki AdÄ±mlar:** Planlanan gelecek faaliyetler

Transkript:
{transcript_text}

ToplantÄ± Ã–zeti:
"""

    print("\nLM Studio'ya toplantÄ± Ã¶zeti Ã§Ä±karma isteÄŸi gÃ¶nderiliyor...")
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": "Sen bir toplantÄ± analiz uzmanÄ±sÄ±n. ToplantÄ± transkriptlerinden kapsamlÄ± Ã¶zetler Ã§Ä±karma konusunda uzmansÄ±n."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=2000
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"LM Studio baÄŸlantÄ± hatasÄ±: {str(e)}"

    print("\nLM Studio'ya aksiyon maddeleri Ã§Ä±karma isteÄŸi gÃ¶nderiliyor...")
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": "Sen bir toplantÄ± analiz uzmanÄ±sÄ±n. ToplantÄ± transkriptlerinden aksiyon maddelerini Ã§Ä±karma konusunda uzmansÄ±n."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=2000
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"LM Studio'dan yanÄ±t alÄ±nÄ±rken hata oluÅŸtu: {e}")
        print("LM Studio'nun Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan ve modelin yÃ¼klendiÄŸinden emin olun.")
        return "GÃ¶rev maddeleri Ã§Ä±karÄ±lamadÄ±."

def parse_lm_studio_to_todojson(lm_studio_text):
    tasks = []
    current_task = {}

    for line in lm_studio_text.splitlines():
        line = line.strip()
        # GÃ¶revi satÄ±rlarÄ± esnek yakalama
        if line.lower().startswith("gÃ¶revi:") or line.startswith("* **GÃ¶revi:**") or line.startswith("* GÃ¶revi:"):
            if current_task:
                tasks.append(current_task)
            description = line.replace("* **GÃ¶revi:**", "").replace("* GÃ¶revi:", "").replace("GÃ¶revi:", "").strip(" -â€“â€”:")
            current_task = {
                "title": description if len(description) <= 100 else description[:97] + "...",
                "description": description,
                "assignees": [],
                "created_date": "",
                "due_date": "",
                "status": "OPEN",
                "priority": "",
                "category": "",
                "tags": [],
                "subtasks": []
            }
        elif line.lower().startswith("kiÅŸi:") or line.startswith("* **KiÅŸi:**") or line.startswith("* KiÅŸi:"):
            if current_task:
                assignee = line.split(":")[1].strip()
                if assignee and assignee.lower() != "belirtilmemiÅŸ":
                    current_task["assignees"].append(assignee)
        elif line.lower().startswith("son tarih:") or line.startswith("* **Son Tarih:**") or line.startswith("* Son Tarih:"):
            if current_task:
                due_raw = line.split(":")[1].strip()
                if due_raw and due_raw.lower() != "belirtilmemiÅŸ":
                    due_iso = None
                    for fmt in ("%Y-%m-%d", "%d.%m.%Y", "%d/%m/%Y", "%d-%m-%Y", "%B %d, %Y", "%d.%m.%y"):
                        try:
                            dt = datetime.strptime(due_raw, fmt)
                            due_iso = dt.isoformat()
                            break
                        except ValueError:
                            continue
                    current_task["due_date"] = due_iso if due_iso else ""

    if current_task:
        tasks.append(current_task)

    return {"tasks": tasks}

def parse_lm_studio_to_todo_backend_api(lm_studio_text, category_id="00000000-0000-0000-0000-000000000000", user_id="00000000-0000-0000-0000-000000000000"):
    """LM Studio Ã§Ä±ktÄ±sÄ±nÄ± todo backend API formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r"""
    tasks = []
    current_task = {}

    for line in lm_studio_text.splitlines():
        line = line.strip()
        # GÃ¶revi satÄ±rlarÄ± esnek yakalama
        if line.lower().startswith("gÃ¶revi:") or line.startswith("* **GÃ¶revi:**") or line.startswith("* GÃ¶revi:"):
            if current_task:
                tasks.append(current_task)
            description = line.replace("* **GÃ¶revi:**", "").replace("* GÃ¶revi:", "").replace("GÃ¶revi:", "").strip(" -â€“â€”:")
            current_task = {
                "categoryId": category_id,
                "title": description if len(description) <= 100 else description[:97] + "...",
                "description": description,
                "isCompleted": False,
                "createdAt": datetime.now().isoformat(),
                "completedAt": None,
                "priority": "Medium",
                "repeatDays": [],
                "repeatType": "None"
            }
        elif line.lower().startswith("kiÅŸi:") or line.startswith("* **KiÅŸi:**") or line.startswith("* KiÅŸi:"):
            # KiÅŸi bilgisi varsa priority'yi High yap
            if current_task:
                assignee = line.split(":")[1].strip()
                if assignee and assignee.lower() != "belirtilmemiÅŸ":
                    current_task["priority"] = "High"
        elif line.lower().startswith("son tarih:") or line.startswith("* **Son Tarih:**") or line.startswith("* Son Tarih:"):
            if current_task:
                due_raw = line.split(":")[1].strip()
                if due_raw and due_raw.lower() != "belirtilmemiÅŸ":
                    # Son tarih varsa priority'yi High yap
                    current_task["priority"] = "High"
                    # CompletedAt alanÄ±nÄ± due date olarak kullan (geÃ§ici Ã§Ã¶zÃ¼m)
                    for fmt in ("%Y-%m-%d", "%d.%m.%Y", "%d/%m/%Y", "%d-%m-%Y", "%B %d, %Y", "%d.%m.%y"):
                        try:
                            dt = datetime.strptime(due_raw, fmt)
                            # Due date'i description'a ekle
                            current_task["description"] += f" (Son Tarih: {dt.strftime('%d.%m.%Y')})"
                            break
                        except ValueError:
                            continue

    if current_task:
        tasks.append(current_task)

    return {"tasks": tasks}

def test_lm_studio_connection():
    """LM Studio baÄŸlantÄ±sÄ±nÄ± test et"""
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[{"role": "user", "content": "Merhaba, Ã§alÄ±ÅŸÄ±yor musun?"}],
            max_tokens=50
        )
        print("âœ“ LM Studio baÄŸlantÄ±sÄ± baÅŸarÄ±lÄ±")
        return True
    except Exception as e:
        print(f"âœ— LM Studio baÄŸlantÄ± hatasÄ±: {e}")
        print("LÃ¼tfen ÅŸunlarÄ± kontrol edin:")
        print("1. LM Studio uygulamasÄ±nÄ±n aÃ§Ä±k olduÄŸunu")
        print("2. openai/gpt-oss-20b modelinin yÃ¼klendiÄŸini")
        print("3. Local server'Ä±n baÅŸlatÄ±ldÄ±ÄŸÄ±nÄ± (http://127.0.0.1:1234)")
        return False

def To_Do_main():
    print("LM Studio baÄŸlantÄ±sÄ± test ediliyor...")
    if not test_lm_studio_connection():
        exit()
    
    if not os.path.exists(TRANSCRIPT_INPUT_FILE):
        print(f"Hata: '{TRANSCRIPT_INPUT_FILE}' dosyasÄ± bulunamadÄ±. Ã–nce transcribe_audio.py dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±n.")
        exit()

    print(f"'{TRANSCRIPT_INPUT_FILE}' dosyasÄ±ndan metin okunuyor...")
    try:
        with open(TRANSCRIPT_INPUT_FILE, "r", encoding="utf-8") as f:
            read_transcript_text = f.read()

        # ToplantÄ± Ã¶zeti Ã§Ä±kar
        meeting_summary = get_meeting_summary_with_lm_studio(read_transcript_text)
        
        print("\n--- ToplantÄ± Ã–zeti ---")
        print(meeting_summary)
        
        # ToplantÄ± Ã¶zetini dosyaya kaydet
        with open(MEETING_SUMMARY_FILE, "w", encoding="utf-8") as f_summary:
            f_summary.write(meeting_summary)
        print(f"ToplantÄ± Ã¶zeti '{MEETING_SUMMARY_FILE}' dosyasÄ±na kaydedildi.")
        
        # Aksiyon maddeleri Ã§Ä±kar
        action_items = get_action_items_with_lm_studio(read_transcript_text)

        print("\n--- Ã‡Ä±karÄ±lan Aksiyon Maddeleri (Ham Metin) ---")
        print(action_items)

        # Ham aksiyon maddelerini dosyaya kaydet
        with open(ACTION_ITEMS_OUTPUT_FILE, "w", encoding="utf-8") as f_out:
            f_out.write(action_items)
        print(f"Ham aksiyon maddeleri '{ACTION_ITEMS_OUTPUT_FILE}' dosyasÄ±na kaydedildi.")

        # JSON formatÄ±na Ã§evir (eski format)
        todo_json = parse_lm_studio_to_todojson(action_items)

        print("\n--- ToDo App Uyumlu JSON (Eski Format) ---")
        print(json.dumps(todo_json, indent=2, ensure_ascii=False))

        with open(ACTION_ITEMS_JSON_FILE, "w", encoding="utf-8") as f_json:
            json.dump(todo_json, f_json, ensure_ascii=False, indent=2)
        print(f"JSON formatÄ±ndaki aksiyon maddeleri '{ACTION_ITEMS_JSON_FILE}' dosyasÄ±na kaydedildi.")

        # Todo Backend API formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r
        todo_backend_json = parse_lm_studio_to_todo_backend_api(action_items)
        
        print("\n--- Todo Backend API Uyumlu JSON ---")
        print(json.dumps(todo_backend_json, indent=2, ensure_ascii=False))
        
        # Todo Backend API formatÄ±nÄ± ayrÄ± dosyaya kaydet
        backend_json_file = "aksiyon_maddeleri_backend.json"
        with open(backend_json_file, "w", encoding="utf-8") as f_backend:
            json.dump(todo_backend_json, f_backend, ensure_ascii=False, indent=2)
        print(f"Backend API formatÄ±ndaki aksiyon maddeleri '{backend_json_file}' dosyasÄ±na kaydedildi.")

        # Todo Backend API'ye gÃ¶nder
        print("\n--- Todo Backend API'ye GÃ¶nderim ---")
        try:
            import requests
            
            # Todo Backend API server'Ä±nÄ±n Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± kontrol et
            try:
                # Ã–nce health check yapalÄ±m (eÄŸer varsa)
                backend_base_url = "http://localhost:5142"  # Todo Backend API URL'i
                
                print(f"Todo Backend API'ye baÄŸlanmaya Ã§alÄ±ÅŸÄ±lÄ±yor: {backend_base_url}")
                
                # GÃ¶revleri toplu olarak gÃ¶nder
                try:
                    # Bulk endpoint iÃ§in format (BulkTaskCreateDto)
                    bulk_data = {
                        "DefaultCategoryId": "01990c81-4b45-7b89-89d1-82b7d41059aa",
                        "Tasks": []
                    }
                    
                    # Her task'Ä± bulk format'a Ã§evir
                    for task in todo_backend_json["tasks"]:
                        # Tarih formatÄ±nÄ± dÃ¼zelt
                        created_date = task["createdAt"][:10] if task["createdAt"] else datetime.now().strftime("%Y-%m-%d")
                        due_date = task["completedAt"][:10] if task["completedAt"] else (datetime.now() + timedelta(days=7)).strftime("%Y-%m-%d")
                        
                        task_data = {
                            "Title": task["title"],
                            "Description": task["description"],
                            "Due_date": due_date,
                            "Status": "OPEN",
                            "Priority": task["priority"]
                        }
                        bulk_data["Tasks"].append(task_data)
                    
                    api_response = requests.post(
                        f"{backend_base_url}/api/Task/bulk",
                        json=bulk_data,
                        headers={"Content-Type": "application/json"},
                        timeout=10,
                        verify=False
                    )
                    
                    if api_response.status_code in [200, 201]:
                        print(f"âœ… {len(bulk_data['Tasks'])} gÃ¶rev baÅŸarÄ±yla eklendi!")
                        print(f"API Response: {api_response.text}")
                    else:
                        print(f"âŒ GÃ¶revler eklenemedi (Status: {api_response.status_code})")
                        print(f"Hata: {api_response.text}")
                        
                except Exception as bulk_error:
                    print(f"âŒ Bulk gÃ¶rev gÃ¶nderim hatasÄ±: {bulk_error}")
                        
                print("ğŸ“‹ Todo Backend API'ye gÃ¶nderim tamamlandÄ±!")
                    
            except requests.exceptions.ConnectionError:
                print("âš ï¸ Todo Backend API server'Ä±na baÄŸlanÄ±lamadÄ±")
                print("Server'Ä±n Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun.")
            except requests.exceptions.Timeout:
                print("âš ï¸ Todo Backend API server'Ä± yanÄ±t vermiyor (timeout)")
                
        except ImportError:
            print("âš ï¸ requests kÃ¼tÃ¼phanesi bulunamadÄ±")
            print("YÃ¼klemek iÃ§in: pip install requests")
        except Exception as api_error:
            print(f"âš ï¸ Todo Backend API gÃ¶nderim hatasÄ±: {api_error}")
    
    except Exception as e:
        print(f"Beklenmeyen hata oluÅŸtu: {e}")

if __name__ == "__main__":
    To_Do_main()