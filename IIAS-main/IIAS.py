# -*- coding: utf-8 -*-

# --- GEREKLÄ° KÃœTÃœPHANELER ---
import os
import json
import requests
import spacy
import cv2
# pytesseract kaldÄ±rÄ±ldÄ±
from moviepy.editor import VideoFileClip
from docx import Document
from elevenlabs import ElevenLabs
from langchain.text_splitter import RecursiveCharacterTextSplitter
from deepface import DeepFace
from collections import Counter
import warnings
import numpy as np
from PIL import Image
import base64
import google.generativeai as genai
import io
from datetime import datetime

# DeepFace ve TensorFlow uyarÄ±larÄ±nÄ± gizle
warnings.filterwarnings("ignore", category=UserWarning)


# Tesseract OCR kaldÄ±rÄ±ldÄ± 

# --- KONFÄ°GÃœRASYON ---
ELEVENLABS_API_KEY = "your_elevenlabs_api_key_here"
GEMINI_API_KEY = "your_gemini_api_key_here"  
INPUT_VIDEO_FILE = "video1723838072.mp4"
TEMP_AUDIO_FILE = "gecici_ses.wav"
TRANSCRIPT_DOCX_FILE = "mulakat_transkripti.docx"
SANIYEDE_ANALIZ_SAYISI = 2
TEMP_FRAME_FILE = "temp_frame.jpg"
TEMP_FACE_FILE = "temp_face.jpg"
LM_STUDIO_API_URL = "http://localhost:1234/v1/chat/completions"
MODEL_NAME = "qwen/qwen3-4b-2507"
FINAL_ANALYSIS_TXT_FILE = "analiz_sonucu.docx"
DURATION_THRESHOLD = 20
    
# DeepFace duygu etiketlerini TÃ¼rkÃ§eye Ã§evirme sÃ¶zlÃ¼ÄŸÃ¼
DUYGU_SOZLUGU = {
    'angry': 'Ã–FKELÄ°',
    'disgust': 'TÄ°KSÄ°NMÄ°Å',
    'fear': 'KORKMUÅ',
    'happy': 'MUTLU',
    'sad': 'ÃœZGÃœN',
    'surprise': 'ÅAÅKIN',
    'neutral': 'DOÄAL'
}

# --- YENÄ° PROMPT'LAR ---
PROMPT_SCORING_DETAILS = """
AÅŸaÄŸÄ±daki mÃ¼lakat Ã¶zetini profesyonel bir Ä°nsan KaynaklarÄ± (Ä°K) uzmanÄ± gibi analiz et.

BÃ–LÃœM 1: PUANLAMA TABLOSU
â€¢ Her kriteri, madde imi (â€¢) ile baÅŸlayan ayrÄ± bir satÄ±rda ve ÅŸu formatta yaz:
â€¢ Kriter AdÄ±: (Puan/5) - {candidate_name}'in [puanÄ±n nedenini aÃ§Ä±klayan kÄ±sa ve tanÄ±mlayÄ±cÄ± bir cÃ¼mle].
â€¢ DeÄŸerlendirilecek Kriterler:
â€¢ Ä°letiÅŸim Becerisi
â€¢ Motivasyon ve Tutku
â€¢ KÃ¼ltÃ¼rel Uyum
â€¢ Analitik/DÃ¼ÅŸÃ¼nsel Beceriler
â€¢ Profesyonel Tutum
â€¢ GeÃ§miÅŸ Deneyim Uyumu
â€¢ Liderlik ve GiriÅŸimcilik
â€¢ ZayÄ±flÄ±klarla BaÅŸa Ã‡Ä±kma Yetisi
â€¢ Uzun Vadeli Potansiyel
â€¢ Genel Etki / Ä°zlenim
â€¢ Analiz Sonu:
â€¢ Genel Ortalama Puan: TÃ¼m puanlarÄ±n ortalamasÄ±nÄ±, ondalÄ±k ayraÃ§ olarak virgÃ¼l kullanarak hesapla. Ã–rnek: (3,86/5)
â€¢ Ä°K Genel Yorum: AdayÄ±n genel potansiyelini ve ana bulgularÄ± Ã¶zetleyen birkaÃ§ cÃ¼mlelik bir paragraf yaz."""

PROMPT_RECRUITER_DETAILS = """
AÅŸaÄŸÄ±daki mÃ¼lakat Ã¶zetini profesyonel bir Ä°nsan KaynaklarÄ± (Ä°K) uzmanÄ± gibi analiz et.

BÃ–LÃœM 2: RECRUITER NOTU TALÄ°MATLARI

â€¢ Analizini, aÅŸaÄŸÄ±daki altÄ± baÅŸlÄ±ÄŸÄ±n tamamÄ±nÄ± madde imi (â€¢) ile baÅŸlayan ayrÄ± satÄ±rlar olarak yapÄ±landÄ±r.
â€¢ Her baÅŸlÄ±ÄŸÄ±n altÄ±na, mÃ¼lakat Ã¶zetinden Ã§Ä±kardÄ±ÄŸÄ±n somut bilgilere (projeler, deneyimler, yetenekler) dayanarak detaylÄ± ve profesyonel bir metin yaz. AdayÄ±n adÄ±nÄ± metin iÃ§inde uygun yerlerde kullan.
â€¢ BaÅŸlÄ±klar ve Ä°Ã§erikleri:
â€¢ Aday AdÄ±: MÃ¼lakat metninden adayÄ±n adÄ±nÄ± Ã§Ä±kar.
â€¢ Pozisyon: MÃ¼lakat metninden adayÄ±n baÅŸvurduÄŸu pozisyonu belirle.
â€¢ Genel Yorum: AdayÄ±n geÃ§miÅŸi, deneyim sÃ¼resi ve genel performansÄ± hakkÄ±nda Ã¶zet bir paragraf yaz.
â€¢ Dikkat Ã‡eken GÃ¼Ã§lÃ¼ YÃ¶nler: AdayÄ±n Ã¶ne Ã§Ä±kan teknik veya sosyal yeteneklerini, projelerden Ã¶rnekler vererek anlat.
â€¢ GeliÅŸtirme AlanlarÄ±: AdayÄ±n hangi konularda kendini geliÅŸtirebileceÄŸini ve potansiyel geliÅŸim alanlarÄ±nÄ± belirt.
â€¢ DeÄŸerlendirme Ã–nerisi: Aday iÃ§in bir sonraki adÄ±mlarÄ± (ikinci gÃ¶rÃ¼ÅŸme, teknik test vb.) ve geliÅŸimini destekleyecek Ã¶nerileri (eÄŸitim, kurs vb.) iÃ§eren bir paragraf yaz.
"""

PROMPT_QA_MATCHING = """
AÅŸaÄŸÄ±daki mÃ¼lakat Ã¶zetini analiz ederek soru-cevap eÅŸleÅŸtirmesi yap.

BÃ–LÃœM 3: SORU-CEVAP ANALÄ°ZÄ°

â€¢ MÃ¼lakat metninden sorulan sorularÄ± ve verilen cevaplarÄ± tespit et.
â€¢ Her soru-cevap Ã§ifti iÃ§in aÅŸaÄŸÄ±daki formatÄ± kullan:
â€¢ Soru Kategorisi: [Teknik/DavranÄ±ÅŸsal/Genel]
â€¢ Soru: [Sorulan soru]
â€¢ Cevap Kalitesi: (Puan/5) - [CevabÄ±n detay seviyesi, doÄŸruluÄŸu ve profesyonelliÄŸi]
â€¢ Cevap Ã–zeti: [AdayÄ±n verdiÄŸi cevabÄ±n kÄ±sa Ã¶zeti]
â€¢ Eksik Noktalar: [CevaplamadÄ±ÄŸÄ± veya yetersiz kaldÄ±ÄŸÄ± konular]

â€¢ Analiz Sonu:
â€¢ Toplam Soru SayÄ±sÄ±: [SayÄ±]
â€¢ En Ä°yi Cevaplanan Sorular: [2-3 soru kategorisi]
â€¢ GeliÅŸim Gerektiren Alanlar: [ZayÄ±f cevaplanan konular]
"""

PROMPT_TECHNICAL_COMPETENCY = """
AÅŸaÄŸÄ±daki mÃ¼lakat Ã¶zetini teknik yetkinlik aÃ§Ä±sÄ±ndan analiz et.

BÃ–LÃœM 4: TEKNÄ°K YETKÄ°NLÄ°K DEÄERLENDÄ°RMESÄ°

â€¢ AdayÄ±n bahsettiÄŸi teknik konularÄ± kategorize et:
â€¢ Programlama Dilleri: [Bahsedilen diller ve deneyim seviyeleri]
â€¢ Teknolojiler/Framework'ler: [KullandÄ±ÄŸÄ± teknolojiler]
â€¢ Projeler: [BahsettiÄŸi projeler ve teknik detaylarÄ±]
â€¢ Problem Ã‡Ã¶zme: [Teknik problemlere yaklaÅŸÄ±mÄ±]
â€¢ Ã–ÄŸrenme YeteneÄŸi: [Yeni teknolojileri Ã¶ÄŸrenme konusundaki tutumu]

â€¢ Her kategori iÃ§in puanlama:
â€¢ Kategori AdÄ±: (Puan/5) - [Yetkinlik seviyesi ve gerekÃ§esi]

â€¢ Teknik Analiz Ã–zeti:
â€¢ GÃ¼Ã§lÃ¼ OlduÄŸu Teknik Alanlar: [En iyi olduÄŸu 2-3 alan]
â€¢ GeliÅŸim AlanlarÄ±: [Eksik veya zayÄ±f olduÄŸu teknik konular]
â€¢ Ã–nerilen Teknik EÄŸitimler: [Hangi konularda eÄŸitim almasÄ± Ã¶nerilir]
"""

PROMPT_SOFT_SKILLS = """
AÅŸaÄŸÄ±daki mÃ¼lakat Ã¶zetini soft skill (yumuÅŸak beceri) aÃ§Ä±sÄ±ndan analiz et.

BÃ–LÃœM 5: SOFT SKÄ°LL ANALÄ°ZÄ°

â€¢ MÃ¼lakat boyunca gÃ¶zlemlenen soft skill'leri deÄŸerlendir:
â€¢ Ä°letiÅŸim TarzÄ±: [AÃ§Ä±k, net, etkili iletiÅŸim kurma yeteneÄŸi]
â€¢ TakÄ±m Ã‡alÄ±ÅŸmasÄ±: [Ekip iÃ§inde Ã§alÄ±ÅŸma deneyimi ve yaklaÅŸÄ±mÄ±]
â€¢ Liderlik: [Liderlik deneyimi ve potansiyeli]
â€¢ Adaptasyon: [DeÄŸiÅŸime uyum saÄŸlama yeteneÄŸi]
â€¢ Zaman YÃ¶netimi: [Proje ve gÃ¶rev yÃ¶netimi becerileri]
â€¢ Stres YÃ¶netimi: [BaskÄ± altÄ±nda Ã§alÄ±ÅŸma yeteneÄŸi]
â€¢ YaratÄ±cÄ±lÄ±k: [YenilikÃ§i Ã§Ã¶zÃ¼mler Ã¼retme yeteneÄŸi]
â€¢ Empati: [BaÅŸkalarÄ±nÄ± anlama ve iÅŸbirliÄŸi kurma]

â€¢ Her soft skill iÃ§in puanlama:
â€¢ Beceri AdÄ±: (Puan/5) - [GÃ¶zlemlenen davranÄ±ÅŸ Ã¶rnekleri]

â€¢ Soft Skill Ã–zeti:
â€¢ En GÃ¼Ã§lÃ¼ Soft Skill'ler: [En geliÅŸmiÅŸ 3 beceri]
â€¢ GeliÅŸim AlanlarÄ±: [GÃ¼Ã§lendirilmesi gereken beceriler]
â€¢ KiÅŸilik Profili: [Genel kiÅŸilik Ã¶zelliklerinin Ã¶zeti]
â€¢ TakÄ±m Uyumu: [Hangi tÃ¼r takÄ±mlarda daha baÅŸarÄ±lÄ± olabileceÄŸi]
"""

# ==============================================================================
# --- YARDIMCI FONKSÄ°YONLAR ---
# ==============================================================================

def extract_candidate_name_from_text(transcript_file_path):
    """
    Transkript dosyasÄ±ndan adayÄ±n ismini LLM ile Ã§Ä±karÄ±r.
    """
    try:
        interview_text = read_text_from_docx(transcript_file_path)
        if not interview_text or not interview_text.strip():
            print(f"HATA: '{transcript_file_path}' dosyasÄ± bulunamadÄ± veya boÅŸ.")
            return None

        prompt_name = f"""
        AÅŸaÄŸÄ±daki mÃ¼lakat metninden adayÄ±n ismini Ã§Ä±kar. Sadece ismi dÃ¶ndÃ¼r, baÅŸka bir ÅŸey yazma.
        Ã–rneÄŸin: "Merhaba, ben Can Bey" -> Can Bey

        --- MÃœLAKAT METNÄ° ---
        {interview_text}
        --- Ä°SÄ°M ---
        """
        candidate_name = get_llm_analysis(prompt_name, MODEL_NAME)
        if candidate_name and candidate_name.strip():
            print(f"Metinden tespit edilen isim: {candidate_name}")
            return candidate_name.strip()
        else:
            print("UyarÄ±: Metinden isim tespit edilemedi.")
            return None
    except Exception as e:
        print(f"HATA: Metinden isim Ã§Ä±karÄ±lÄ±rken hata: {e}")
        return None

def extract_frame_and_name(video_path, text_name, max_duration=120.0):
    """
    GeliÅŸmiÅŸ yÃ¼z tespit algoritmasÄ± ile videodan en iyi yÃ¼z gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼ Ã§Ä±karÄ±r.
    Ã‡oklu yÃ¼z tespit yÃ¶ntemi ve kalite kontrolÃ¼ iÃ§erir.
    """
    try:
        video = cv2.VideoCapture(video_path)
        if not video.isOpened():
            print(f"HATA: '{video_path}' videosu aÃ§Ä±lamadÄ±.")
            return None, None
        
        fps = video.get(cv2.CAP_PROP_FPS) or 30
        max_frames = int(max_duration * fps)
        frame_interval = int(fps * 1)  # Her saniyede bir kare (daha sÄ±k kontrol)
        frame_num = 0
        final_name = text_name
        best_face_data = None
        best_face_score = 0

        print(f"GeliÅŸmiÅŸ yÃ¼z tespit baÅŸlatÄ±lÄ±yor... (Ä°lk {max_duration} saniye taranacak)")

        while frame_num < max_frames:
            ret, frame = video.read()
            if not ret:
                break

            if frame_num % frame_interval == 0:
                timestamp = frame_num / fps
                
                # Ã‡oklu yÃ¼z tespit yÃ¶ntemi
                face_data = detect_best_face_in_frame(frame, timestamp)
                
                if face_data and face_data['quality_score'] > best_face_score:
                    best_face_data = face_data
                    best_face_score = face_data['quality_score']
                    print(f"Daha iyi yÃ¼z bulundu (skor: {best_face_score:.2f}, zaman: {timestamp:.1f}s)")

            frame_num += 1

        video.release()
        
        # En iyi yÃ¼zÃ¼ kaydet
        face_image_path = None
        if best_face_data:
            face_image_path = save_best_face(best_face_data)
            print(f"En iyi yÃ¼z gÃ¶rÃ¼ntÃ¼sÃ¼ kaydedildi: {face_image_path}")
            print(f"Kalite skoru: {best_face_score:.2f}")
        else:
            print("UyarÄ±: HiÃ§bir yÃ¼z tespit edilemedi.")

        return final_name, face_image_path
    except Exception as e:
        print(f"HATA: GeliÅŸmiÅŸ yÃ¼z tespit sÄ±rasÄ±nda hata: {e}")
        return None, None

def detect_best_face_in_frame(frame, timestamp):
    """
    Bir karede en iyi yÃ¼zÃ¼ tespit eder ve kalite skorunu hesaplar.
    """
    try:
        # DeepFace ile yÃ¼z tespiti
        analysis = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False, silent=True)
        
        if isinstance(analysis, list) and len(analysis) > 0:
            face_info = analysis[0]
            face_region = face_info['region']
            x, y, w, h = face_region['x'], face_region['y'], face_region['w'], face_region['h']
            
            # YÃ¼z gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼ Ã§Ä±kar
            face_img = frame[y:y+h, x:x+w]
            
            # Kalite kontrolÃ¼
            quality_score = calculate_face_quality(face_img, w, h)
            
            return {
                'face_image': face_img,
                'region': face_region,
                'quality_score': quality_score,
                'timestamp': timestamp,
                'emotion_data': face_info.get('emotion', {})
            }
    except Exception:
        pass
    
    return None

def calculate_face_quality(face_img, width, height):
    """
    YÃ¼z gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼n kalitesini hesaplar (0-100 arasÄ± skor).
    """
    try:
        # Boyut skoru (bÃ¼yÃ¼k yÃ¼zler daha iyi)
        size_score = min(100, (width * height) / 10000 * 100)
        
        # Netlik skoru (Laplacian varyansÄ±)
        gray = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        sharpness_score = min(100, laplacian_var / 500 * 100)
        
        # ParlaklÄ±k skoru (Ã§ok karanlÄ±k veya Ã§ok aydÄ±nlÄ±k deÄŸil)
        brightness = np.mean(gray)
        brightness_score = 100 - abs(brightness - 128) / 128 * 100
        
        # Toplam kalite skoru
        total_score = (size_score * 0.4 + sharpness_score * 0.4 + brightness_score * 0.2)
        
        return total_score
    except Exception:
        return 0

def save_best_face(face_data):
    """
    En iyi yÃ¼z gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼ kaydeder ve dosya yolunu dÃ¶ndÃ¼rÃ¼r.
    """
    try:
        face_img = face_data['face_image']
        
        # GÃ¶rÃ¼ntÃ¼ iyileÅŸtirme
        enhanced_face = enhance_face_image(face_img)
        
        # DosyayÄ± kaydet
        cv2.imwrite(TEMP_FACE_FILE, enhanced_face)
        
        return TEMP_FACE_FILE
    except Exception as e:
        print(f"YÃ¼z kaydetme hatasÄ±: {e}")
        return None

def enhance_face_image(face_img):
    """
    YÃ¼z gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼ iyileÅŸtirir (kontrast, parlaklÄ±k, netlik).
    """
    try:
        # Histogram eÅŸitleme
        lab = cv2.cvtColor(face_img, cv2.COLOR_BGR2LAB)
        lab[:,:,0] = cv2.equalizeHist(lab[:,:,0])
        enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
        
        # Hafif keskinleÅŸtirme
        kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
        sharpened = cv2.filter2D(enhanced, -1, kernel)
        
        # Orijinal ile karÄ±ÅŸÄ±m (Ã§ok agresif olmamasÄ± iÃ§in)
        result = cv2.addWeighted(enhanced, 0.7, sharpened, 0.3, 0)
        
        return result
    except Exception:
        return face_img

# compare_names fonksiyonu kaldÄ±rÄ±ldÄ± (OCR ile birlikte)

def analyze_character_from_image(face_image_path):
    """
    GeliÅŸmiÅŸ Gemini 2.5 Flash ile adayÄ±n yÃ¼z gÃ¶rÃ¼ntÃ¼sÃ¼ne dayalÄ± kapsamlÄ± karakter analizi yapar.
    """
    try:
        print(f"GeliÅŸmiÅŸ gÃ¶rsel analiz baÅŸlatÄ±lÄ±yor: '{face_image_path}'")

        # Gemini API'sini yapÄ±landÄ±r
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel("gemini-2.5-flash")

        # GÃ¶rseli base64 formatÄ±na Ã§evir
        image_base64 = image_to_base64(face_image_path)
        if image_base64 is None:
            print("GÃ¶rsel yÃ¼klenemedi. Analiz atlanÄ±yor.")
            return None

        # GeliÅŸmiÅŸ analiz prompt'u
        prompt = """
        Bu gÃ¶rsel bir mÃ¼lakat adayÄ±nÄ±n profesyonel ortamdaki gÃ¶rÃ¼ntÃ¼sÃ¼dÃ¼r. LÃ¼tfen aÅŸaÄŸÄ±daki kategorilerde detaylÄ± analiz yapÄ±n:

        ğŸ¯ **PROFESYONEL GÃ–RÃœNÃœM ANALÄ°ZÄ°**
        
        **1. KÄ±yafet ve Grooming (25 puan)**
        - KÄ±yafet seÃ§imi ve uygunluÄŸu (iÅŸ ortamÄ±na uygun mu?)
        - Temizlik ve dÃ¼zenlilik
        - Renk uyumu ve stil
        - SaÃ§ dÃ¼zeni ve genel bakÄ±m
        - Aksesuar kullanÄ±mÄ± (varsa)
        
        **2. Beden Dili ve PostÃ¼r (25 puan)**
        - OturuÅŸ/duruÅŸ pozisyonu
        - Omuz hizasÄ± ve sÄ±rt dÃ¼zlÃ¼ÄŸÃ¼
        - El pozisyonlarÄ± ve jestler
        - Genel vÃ¼cut dili (aÃ§Ä±k/kapalÄ±)
        - Kendine gÃ¼ven yansÄ±masÄ±
        
        **3. YÃ¼z Ä°fadesi ve GÃ¶z Kontaktu (25 puan)**
        - YÃ¼z ifadesinin genel tonu
        - GÃ¶z kontaktu kalitesi
        - GÃ¼lÃ¼mseme ve mimikler
        - Stres/gerginlik belirtileri
        - Odaklanma ve dikkat
        
        **4. Genel Ä°lk Ä°zlenim (25 puan)**
        - Profesyonellik dÃ¼zeyi
        - HazÄ±rlÄ±k ve Ã¶zen gÃ¶sterme
        - Ã–zgÃ¼ven ve kararlÄ±lÄ±k
        - Ä°ÅŸ ortamÄ±na uyum potansiyeli
        - GÃ¼venilirlik hissi
        
        ğŸ“Š **PUANLAMA SÄ°STEMÄ°**
        Her kategori iÃ§in 0-25 puan verin ve toplam 100 Ã¼zerinden deÄŸerlendirin.
        
        ğŸ“ **RAPOR FORMATI**
        Her kategori iÃ§in:
        - GÃ¶zlemlenen Ã¶zellikler
        - Puan ve gerekÃ§esi
        - Ã–neriler (varsa)
        
        âš ï¸ **Ã–NEMLI NOTLAR**
        - Sadece gÃ¶rsel olarak gÃ¶zlemlenebilir unsurlarÄ± deÄŸerlendirin
        - Ã–nyargÄ±sÄ±z ve objektif olun
        - Her deÄŸerlendirmenin gÃ¶rsel kanÄ±tÄ±nÄ± belirtin
        - KÃ¼ltÃ¼rel farklÄ±lÄ±klarÄ± gÃ¶z Ã¶nÃ¼nde bulundurun
        
        LÃ¼tfen analizi TÃ¼rkÃ§e olarak yapÄ±n ve profesyonel bir dil kullanÄ±n.
        """

        # GÃ¶rseli ve prompt'u Gemini API'sine gÃ¶nder
        response = model.generate_content([
            prompt,
            {
                "mime_type": "image/jpeg",
                "data": image_base64
            }
        ])
        
        analysis = response.text
        print("GeliÅŸmiÅŸ gÃ¶rsel analiz baÅŸarÄ±yla tamamlandÄ±.")
        
        # Analiz sonucunu formatla
        formatted_analysis = format_visual_analysis(analysis)
        
        return formatted_analysis
    except Exception as e:
        print(f"HATA: GeliÅŸmiÅŸ gÃ¶rÃ¼ntÃ¼ analizi sÄ±rasÄ±nda hata: {e}")
        return None

def image_to_base64(image_path):
    """
    GÃ¶rÃ¼ntÃ¼ dosyasÄ±nÄ± base64 formatÄ±na Ã§evirir.
    """
    try:
        with Image.open(image_path) as img:
            # GÃ¶rÃ¼ntÃ¼ boyutunu optimize et (Ã§ok bÃ¼yÃ¼kse kÃ¼Ã§Ã¼lt)
            max_size = (800, 800)
            img.thumbnail(max_size, Image.Resampling.LANCZOS)
            
            buffered = io.BytesIO()
            img.save(buffered, format="JPEG", quality=85)
            return base64.b64encode(buffered.getvalue()).decode("utf-8")
    except FileNotFoundError:
        print(f"Hata: GÃ¶rsel dosyasÄ± bulunamadÄ±: {image_path}")
        return None
    except Exception as e:
        print(f"GÃ¶rsel iÅŸleme hatasÄ±: {e}")
        return None

def format_visual_analysis(analysis):
    """
    GÃ¶rsel analiz sonucunu formatlar ve yapÄ±landÄ±rÄ±r.
    """
    try:
        # Analiz baÅŸlÄ±ÄŸÄ± ekle
        formatted = "\n" + "="*60 + "\n"
        formatted += "           GÃ–RSEL TABALLI PROFESYONEL ANALÄ°Z\n"
        formatted += "="*60 + "\n\n"
        
        # Ana analizi ekle
        formatted += analysis
        
        # Analiz tarihi ekle
        from datetime import datetime
        formatted += "\n\n" + "-"*40
        formatted += f"\nAnaliz Tarihi: {datetime.now().strftime('%d.%m.%Y %H:%M')}\n"
        formatted += "Analiz YÃ¶ntemi: Gemini 2.5 Flash - GeliÅŸmiÅŸ GÃ¶rsel AI\n"
        
        return formatted
    except Exception:
        return analysis

def videodaki_duygulari_analiz_et(video_path, saniyede_kontrol=2):
    """GeliÅŸmiÅŸ video duygu analizi - optimize edilmiÅŸ frame iÅŸleme ve duygu tespiti."""
    print("\nğŸ­ GeliÅŸmiÅŸ video duygu analizi baÅŸlatÄ±lÄ±yor...")
    
    video = cv2.VideoCapture(video_path)
    if not video.isOpened():
        print("âŒ Video dosyasÄ± aÃ§Ä±lamadÄ±!")
        return []
    
    # Video bilgilerini al
    fps = video.get(cv2.CAP_PROP_FPS)
    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = total_frames / fps if fps > 0 else 0
    
    print(f"ğŸ“¹ Video Bilgileri: {duration:.1f}s, {fps:.1f} FPS, {total_frames} frame")
    
    frame_interval = max(1, int(fps / saniyede_kontrol)) if saniyede_kontrol > 0 and fps > 0 else int(fps)
    
    duygu_zaman_cizelgesi = []
    frame_num = 0
    processed_frames = 0
    failed_detections = 0
    
    # Ä°lerleme takibi
    progress_interval = max(1, total_frames // 20)  # %5'lik aralÄ±klarla ilerleme
    
    while video.isOpened():
        ret, frame = video.read()
        if not ret:
            break

        if frame_num % frame_interval == 0:
            try:
                # Frame kalitesini kontrol et
                if is_frame_suitable_for_emotion_analysis(frame):
                    analysis = DeepFace.analyze(
                        frame,
                        actions=['emotion'],
                        enforce_detection=False,
                        silent=True
                    )
                    
                    if isinstance(analysis, list) and len(analysis) > 0:
                        emotion_data = analysis[0]
                        dominant_emotion_en = emotion_data['dominant_emotion']
                        dominant_emotion_tr = DUYGU_SOZLUGU.get(dominant_emotion_en, dominant_emotion_en.upper())
                        
                        # Duygu gÃ¼ven skorunu al
                        confidence = emotion_data['emotion'].get(dominant_emotion_en, 0)
                        
                        timestamp = frame_num / fps
                        
                        duygu_entry = {
                            'zaman': timestamp,
                            'duygu': dominant_emotion_tr,
                            'guven_skoru': confidence,
                            'tum_duygular': {DUYGU_SOZLUGU.get(k, k): v for k, v in emotion_data['emotion'].items()}
                        }
                        
                        duygu_zaman_cizelgesi.append(duygu_entry)
                        processed_frames += 1
                    else:
                        failed_detections += 1
                else:
                    failed_detections += 1
                    
            except Exception as e:
                failed_detections += 1
                if frame_num % (frame_interval * 10) == 0:  # Her 10 frame'de bir hata logla
                    print(f"âš ï¸ Frame {frame_num} analiz hatasÄ±: {str(e)[:50]}...")
        
        # Ä°lerleme gÃ¶ster
        if frame_num % progress_interval == 0:
            progress = (frame_num / total_frames) * 100
            print(f"ğŸ“Š Ä°lerleme: {progress:.1f}% ({processed_frames} baÅŸarÄ±lÄ±, {failed_detections} baÅŸarÄ±sÄ±z)")
        
        frame_num += 1

    video.release()
    
    # SonuÃ§ Ã¶zeti
    print(f"\nâœ… Duygu analizi tamamlandÄ±!")
    print(f"ğŸ“ˆ Toplam analiz edilen frame: {processed_frames}")
    print(f"âŒ BaÅŸarÄ±sÄ±z tespit: {failed_detections}")
    print(f"ğŸ¯ BaÅŸarÄ± oranÄ±: {(processed_frames/(processed_frames+failed_detections)*100):.1f}%" if (processed_frames+failed_detections) > 0 else "ğŸ¯ BaÅŸarÄ± oranÄ±: 0%")
    
    # Duygu daÄŸÄ±lÄ±mÄ±nÄ± analiz et
    if duygu_zaman_cizelgesi:
        emotion_summary = analyze_emotion_distribution(duygu_zaman_cizelgesi)
        print(f"ğŸ­ Dominant duygu: {emotion_summary['dominant']} ({emotion_summary['dominant_percentage']:.1f}%)")
    
    return duygu_zaman_cizelgesi

def is_frame_suitable_for_emotion_analysis(frame):
    """Frame'in duygu analizi iÃ§in uygun olup olmadÄ±ÄŸÄ±nÄ± kontrol eder."""
    try:
        # Frame boyutunu kontrol et
        if frame is None or frame.size == 0:
            return False
        
        height, width = frame.shape[:2]
        if height < 100 or width < 100:
            return False
        
        # ParlaklÄ±k kontrolÃ¼ (Ã§ok karanlÄ±k veya Ã§ok parlak frameler)
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        mean_brightness = np.mean(gray)
        
        # Ã‡ok karanlÄ±k (< 30) veya Ã§ok parlak (> 220) frameler
        if mean_brightness < 30 or mean_brightness > 220:
            return False
        
        # BulanÄ±klÄ±k kontrolÃ¼ (Laplacian variance)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        if laplacian_var < 100:  # Ã‡ok bulanÄ±k
            return False
        
        return True
    except Exception:
        return False

def analyze_emotion_distribution(emotion_timeline):
    """Duygu zaman Ã§izelgesini analiz eder ve daÄŸÄ±lÄ±m bilgisi verir."""
    try:
        emotions = [entry['duygu'] for entry in emotion_timeline]
        emotion_counts = Counter(emotions)
        total_count = len(emotions)
        
        if total_count == 0:
            return {'dominant': 'BELÄ°RSÄ°Z', 'dominant_percentage': 0, 'distribution': {}}
        
        dominant_emotion = emotion_counts.most_common(1)[0][0]
        dominant_count = emotion_counts[dominant_emotion]
        dominant_percentage = (dominant_count / total_count) * 100
        
        distribution = {emotion: (count / total_count) * 100 for emotion, count in emotion_counts.items()}
        
        return {
            'dominant': dominant_emotion,
            'dominant_percentage': dominant_percentage,
            'distribution': distribution,
            'total_analyzed_frames': total_count
        }
    except Exception:
        return {'dominant': 'BELÄ°RSÄ°Z', 'dominant_percentage': 0, 'distribution': {}}

def assess_video_quality(video_path):
    """Video kalitesini kapsamlÄ± olarak deÄŸerlendirir."""
    print("\nğŸ” Video kalitesi deÄŸerlendiriliyor...")
    
    try:
        video = cv2.VideoCapture(video_path)
        if not video.isOpened():
            return {'overall_score': 0, 'issues': ['Video aÃ§Ä±lamadÄ±'], 'recommendations': ['Video dosyasÄ±nÄ± kontrol edin']}
        
        # Video Ã¶zelliklerini al
        fps = video.get(cv2.CAP_PROP_FPS)
        width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / fps if fps > 0 else 0
        
        quality_metrics = {
            'resolution_score': 0,
            'fps_score': 0,
            'duration_score': 0,
            'brightness_score': 0,
            'sharpness_score': 0,
            'stability_score': 0
        }
        
        issues = []
        recommendations = []
        
        # Ã‡Ã¶zÃ¼nÃ¼rlÃ¼k deÄŸerlendirmesi
        total_pixels = width * height
        if total_pixels >= 1920 * 1080:  # Full HD+
            quality_metrics['resolution_score'] = 100
        elif total_pixels >= 1280 * 720:  # HD
            quality_metrics['resolution_score'] = 80
        elif total_pixels >= 854 * 480:  # SD
            quality_metrics['resolution_score'] = 60
        else:
            quality_metrics['resolution_score'] = 30
            issues.append(f"DÃ¼ÅŸÃ¼k Ã§Ã¶zÃ¼nÃ¼rlÃ¼k: {width}x{height}")
            recommendations.append("En az 720p (1280x720) Ã§Ã¶zÃ¼nÃ¼rlÃ¼k kullanÄ±n")
        
        # FPS deÄŸerlendirmesi
        if fps >= 30:
            quality_metrics['fps_score'] = 100
        elif fps >= 24:
            quality_metrics['fps_score'] = 80
        elif fps >= 15:
            quality_metrics['fps_score'] = 60
        else:
            quality_metrics['fps_score'] = 30
            issues.append(f"DÃ¼ÅŸÃ¼k FPS: {fps:.1f}")
            recommendations.append("En az 24 FPS kullanÄ±n")
        
        # SÃ¼re deÄŸerlendirmesi
        if 60 <= duration <= 1800:  # 1-30 dakika ideal
            quality_metrics['duration_score'] = 100
        elif 30 <= duration <= 3600:  # 30 saniye - 1 saat kabul edilebilir
            quality_metrics['duration_score'] = 80
        else:
            quality_metrics['duration_score'] = 50
            if duration < 30:
                issues.append(f"Ã‡ok kÄ±sa video: {duration:.1f}s")
                recommendations.append("En az 30 saniye video kaydedin")
            else:
                issues.append(f"Ã‡ok uzun video: {duration/60:.1f} dakika")
                recommendations.append("Video sÃ¼resini 30 dakika altÄ±nda tutun")
        
        # Frame kalitesi analizi (Ã¶rnekleme ile)
        sample_frames = min(50, total_frames // 10)  # En fazla 50 frame Ã¶rnekle
        frame_interval = max(1, total_frames // sample_frames)
        
        brightness_scores = []
        sharpness_scores = []
        
        for i in range(0, total_frames, frame_interval):
            video.set(cv2.CAP_PROP_POS_FRAMES, i)
            ret, frame = video.read()
            if not ret:
                break
            
            # ParlaklÄ±k analizi
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            brightness = np.mean(gray)
            
            # Optimal parlaklÄ±k aralÄ±ÄŸÄ±: 80-180
            if 80 <= brightness <= 180:
                brightness_score = 100
            elif 50 <= brightness <= 220:
                brightness_score = 70
            else:
                brightness_score = 30
            brightness_scores.append(brightness_score)
            
            # Keskinlik analizi (Laplacian variance)
            laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
            if laplacian_var > 500:
                sharpness_score = 100
            elif laplacian_var > 200:
                sharpness_score = 80
            elif laplacian_var > 100:
                sharpness_score = 60
            else:
                sharpness_score = 30
            sharpness_scores.append(sharpness_score)
        
        video.release()
        
        # Ortalama skorlarÄ± hesapla
        quality_metrics['brightness_score'] = np.mean(brightness_scores) if brightness_scores else 0
        quality_metrics['sharpness_score'] = np.mean(sharpness_scores) if sharpness_scores else 0
        quality_metrics['stability_score'] = 90  # Basit varsayÄ±m, geliÅŸtirilebilir
        
        # Kalite sorunlarÄ±nÄ± tespit et
        if quality_metrics['brightness_score'] < 70:
            issues.append("ParlaklÄ±k sorunlarÄ± tespit edildi")
            recommendations.append("Daha iyi aydÄ±nlatma kullanÄ±n")
        
        if quality_metrics['sharpness_score'] < 70:
            issues.append("BulanÄ±klÄ±k/odak sorunlarÄ± tespit edildi")
            recommendations.append("KamerayÄ± sabit tutun ve odaÄŸÄ± kontrol edin")
        
        # Genel skor hesapla
        overall_score = np.mean(list(quality_metrics.values()))
        
        quality_assessment = {
            'overall_score': round(overall_score, 1),
            'metrics': quality_metrics,
            'video_info': {
                'resolution': f"{width}x{height}",
                'fps': fps,
                'duration': duration,
                'total_frames': total_frames
            },
            'issues': issues,
            'recommendations': recommendations,
            'quality_level': get_quality_level(overall_score)
        }
        
        print(f"ğŸ“Š Video kalitesi: {quality_assessment['quality_level']} ({overall_score:.1f}/100)")
        
        return quality_assessment
        
    except Exception as e:
        print(f"âŒ Video kalitesi deÄŸerlendirme hatasÄ±: {e}")
        return {
            'overall_score': 0,
            'issues': [f'DeÄŸerlendirme hatasÄ±: {str(e)}']
        }

def get_quality_level(score):
    """Skor bazÄ±nda kalite seviyesi dÃ¶ndÃ¼rÃ¼r."""
    if score >= 90:
        return "MÃ¼kemmel"
    elif score >= 80:
        return "Ã‡ok Ä°yi"
    elif score >= 70:
        return "Ä°yi"
    elif score >= 60:
        return "Orta"
    elif score >= 50:
        return "ZayÄ±f"
    else:
        return "Ã‡ok ZayÄ±f"

def assess_image_quality(image_path):
    """GÃ¶rÃ¼ntÃ¼ kalitesini deÄŸerlendirir."""
    try:
        img = cv2.imread(image_path)
        if img is None:
            return {'score': 0, 'issues': ['GÃ¶rÃ¼ntÃ¼ yÃ¼klenemedi']}
        
        height, width = img.shape[:2]
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # Ã‡Ã¶zÃ¼nÃ¼rlÃ¼k skoru
        total_pixels = width * height
        if total_pixels >= 500000:  # ~700x700+
            resolution_score = 100
        elif total_pixels >= 200000:  # ~450x450+
            resolution_score = 80
        else:
            resolution_score = 50
        
        # ParlaklÄ±k skoru
        brightness = np.mean(gray)
        if 80 <= brightness <= 180:
            brightness_score = 100
        elif 50 <= brightness <= 220:
            brightness_score = 70
        else:
            brightness_score = 30
        
        # Keskinlik skoru
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        if laplacian_var > 500:
            sharpness_score = 100
        elif laplacian_var > 200:
            sharpness_score = 80
        else:
            sharpness_score = 50
        
        overall_score = (resolution_score + brightness_score + sharpness_score) / 3
        
        issues = []
        if resolution_score < 80:
            issues.append("DÃ¼ÅŸÃ¼k Ã§Ã¶zÃ¼nÃ¼rlÃ¼k")
        if brightness_score < 70:
            issues.append("ParlaklÄ±k problemi")
        if sharpness_score < 70:
            issues.append("BulanÄ±klÄ±k")
        
        return {
            'score': round(overall_score, 1),
            'resolution_score': resolution_score,
            'brightness_score': brightness_score,
            'sharpness_score': sharpness_score,
            'dimensions': f"{width}x{height}",
            'issues': issues,
            'quality_level': get_quality_level(overall_score)
        }
        
    except Exception as e:
        return {'score': 0, 'issues': [f'DeÄŸerlendirme hatasÄ±: {str(e)}']}

def konusmacilari_ayir_ve_cumlele(words_data, duygu_cizelgesi):
    """
    ElevenLabs'ten gelen kelime bazlÄ± diarizasyon verisini iÅŸler.
    KonuÅŸmacÄ± etiketlerine gÃ¶re metni gruplar, spaCy ile cÃ¼mlelere ayÄ±rÄ±r ve duygu analizi ekler.
    """
    if not words_data:
        print("\nKonuÅŸmacÄ± ayÄ±rmak iÃ§in kelime verisi bulunamadÄ±.")
        return []

    speaker_map = {}
    next_speaker_num = 1
    current_speaker_id_raw = None
    current_speaker_mapped_label = None
    current_speaker_words_buffer = []
    all_speaker_utterances_combined = []

    for word_obj in words_data:
        word_text = word_obj.text
        raw_speaker_id = word_obj.speaker_id
        start_time = word_obj.start
        end_time = word_obj.end

        if raw_speaker_id not in speaker_map:
            speaker_map[raw_speaker_id] = f"KonuÅŸmacÄ± {next_speaker_num}"
            next_speaker_num += 1

        mapped_speaker_label = speaker_map[raw_speaker_id]

        if current_speaker_id_raw is None:
            current_speaker_id_raw = raw_speaker_id
            current_speaker_mapped_label = mapped_speaker_label
        elif raw_speaker_id != current_speaker_id_raw:
            if current_speaker_words_buffer:
                all_speaker_utterances_combined.append({
                    'speaker': current_speaker_mapped_label,
                    'text_combined': " ".join([w['text'] for w in current_speaker_words_buffer]).strip(),
                    'start_time': current_speaker_words_buffer[0]['start'],
                    'end_time': current_speaker_words_buffer[-1]['end']
                })
            current_speaker_id_raw = raw_speaker_id
            current_speaker_mapped_label = mapped_speaker_label
            current_speaker_words_buffer = []

        current_speaker_words_buffer.append({'text': word_text, 'start': start_time, 'end': end_time})

    if current_speaker_words_buffer:
        all_speaker_utterances_combined.append({
            'speaker': current_speaker_mapped_label,
            'text_combined': " ".join([w['text'] for w in current_speaker_words_buffer]).strip(),
            'start_time': current_speaker_words_buffer[0]['start'],
            'end_time': current_speaker_words_buffer[-1]['end']
        })

    final_diarized_sentences = []
    try:
        nlp = spacy.load("xx_ent_wiki_sm")
        if "sentencizer" not in nlp.pipe_names:
            nlp.add_pipe("sentencizer")
    except OSError:
        print("\nspaCy modeli 'xx_ent_wiki_sm' bulunamadÄ±.")
        print("LÃ¼tfen 'python -m spacy download xx_ent_wiki_sm' komutunu Ã§alÄ±ÅŸtÄ±rÄ±n.")
        return []
    except Exception as e:
        print(f"spaCy modeli yÃ¼klenirken bir hata oluÅŸtu: {e}")
        return []

    for entry in all_speaker_utterances_combined:
        doc = nlp(entry['text_combined'])
        sentences_for_speaker = [sent.text.strip() for sent in doc.sents if sent.text.strip()]
        start_time = entry['start_time']
        end_time = entry['end_time']
        duration = end_time - start_time
        sentences_count = len(sentences_for_speaker)

        if sentences_count == 0:
            continue

        for i, sent in enumerate(sentences_for_speaker):
            sent_start = start_time + (i * duration / sentences_count)
            sent_end = start_time + ((i + 1) * duration / sentences_count)
            ilgili_duygular = [d['duygu'] for d in duygu_cizelgesi if sent_start <= d['zaman'] <= sent_end]
            dominant_duygu = Counter(ilgili_duygular).most_common(1)[0][0] if ilgili_duygular else "BELÄ°RSÄ°Z"

            final_diarized_sentences.append({
                "konusmaci": entry['speaker'],
                "diyalog": sent,
                "duygu": dominant_duygu,
                "baslangic": sent_start,
                "bitis": sent_end
            })

    return final_diarized_sentences

def read_text_from_docx(file_path):
    """
    Bir .docx dosyasÄ±ndaki tÃ¼m metni okur ve tek bir metin bloÄŸu olarak dÃ¶ndÃ¼rÃ¼r.
    """
    try:
        doc = Document(file_path)
        full_text = [para.text for para in doc.paragraphs]
        return '\n'.join(full_text)
    except Exception as e:
        print(f"HATA: '{file_path}' dosyasÄ± okunurken hata oluÅŸtu: {e}")
        return None

def get_llm_analysis(prompt, model_name):
    """
    LM Studio API aracÄ±lÄ±ÄŸÄ±yla yerel LLM'e bir prompt gÃ¶nderir ve analizi alÄ±r.
    """
    payload = {
        "model": model_name,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.7,
        "max_tokens": 2048
    }
    try:
        response = requests.post(LM_STUDIO_API_URL, json=payload)
        response.raise_for_status()
        response_data = response.json()
        if "choices" in response_data and response_data["choices"]:
            return response_data["choices"][0]["message"]["content"]
        else:
            print(f"HATA: API yanÄ±tÄ±nda 'choices' anahtarÄ± bulunamadÄ± veya boÅŸ. YanÄ±t: {response_data}")
            return None
    except requests.exceptions.ConnectionError:
        print("HATA: LM Studio API sunucusuna baÄŸlanÄ±lamadÄ±. LÃ¼tfen sunucunun Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun.")
        return None
    except requests.exceptions.HTTPError as http_err:
        print(f"HATA: API isteÄŸi sÄ±rasÄ±nda HTTP hatasÄ±: {http_err}\nYanÄ±t Ä°Ã§eriÄŸi: {response.text}")
        return None
    except Exception as e:
        print(f"HATA: Analiz sÄ±rasÄ±nda beklenmedik bir hata oluÅŸtu: {e}")
        return None

def write_analysis_to_txt(file_path, analysis_scoring, analysis_recruiter, image_analysis, candidate_name, analysis_qa=None, analysis_technical=None, analysis_soft_skills=None):
    """
    Analiz sonuÃ§larÄ±nÄ± yeni bir .docx dosyasÄ±na yazar, dÃ¼zgÃ¼n formatlanmÄ±ÅŸ ÅŸekilde.
    """
    try:
        from docx import Document
        from docx.shared import Inches
        from docx.enum.text import WD_ALIGN_PARAGRAPH
        
        # Yeni bir Word belgesi oluÅŸtur
        doc = Document()
        
        # BaÅŸlÄ±k
        title = doc.add_heading('MÃœLAKAT ANALÄ°ZÄ° SONUCU', level=1)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER
        
        doc.add_paragraph('=' * 50)
        doc.add_paragraph()
        
        # 1. Aday DeÄŸerlendirme Puanlama Tablosu
        heading1 = doc.add_heading('1. ADAY DEÄERLENDÄ°RME PUANLAMA TABLOSU', level=2)
        doc.add_paragraph('-' * 45)
        doc.add_paragraph(analysis_scoring)
        doc.add_paragraph()
        
        # 2. Recruiter Notu
        heading2 = doc.add_heading('2. RECRUITER NOTU', level=2)
        doc.add_paragraph('-' * 17)
        doc.add_paragraph(analysis_recruiter)
        doc.add_paragraph()
        
        # 3. GÃ¶rÃ¼ntÃ¼ TabanlÄ± Karakter Analizi
        heading3 = doc.add_heading('3. GÃ–RÃœNTÃœ TABANLI KARAKTER ANALÄ°ZÄ°', level=2)
        doc.add_paragraph('-' * 35)
        if image_analysis:
            doc.add_paragraph(image_analysis)
        else:
            doc.add_paragraph(f"{candidate_name} iÃ§in gÃ¶rÃ¼ntÃ¼ tabanlÄ± analiz yapÄ±lamadÄ±.")
        doc.add_paragraph()
        
        # 4. Soru-Cevap Analizi
        if analysis_qa:
            heading4 = doc.add_heading('4. SORU-CEVAP ANALÄ°ZÄ°', level=2)
            doc.add_paragraph('-' * 22)
            doc.add_paragraph(analysis_qa)
            doc.add_paragraph()
        
        # 5. Teknik Yetkinlik DeÄŸerlendirmesi
        if analysis_technical:
            heading5 = doc.add_heading('5. TEKNÄ°K YETKÄ°NLÄ°K DEÄERLENDÄ°RMESÄ°', level=2)
            doc.add_paragraph('-' * 37)
            doc.add_paragraph(analysis_technical)
            doc.add_paragraph()
        
        # 6. Soft Skill Analizi
        if analysis_soft_skills:
            heading6 = doc.add_heading('6. SOFT SKILL ANALÄ°ZÄ°', level=2)
            doc.add_paragraph('-' * 22)
            doc.add_paragraph(analysis_soft_skills)
        
        # DosyayÄ± kaydet
        doc.save(file_path)
        print(f"\nAnaliz sonuÃ§larÄ± '{file_path}' dosyasÄ±na baÅŸarÄ±yla kaydedildi.")
        
    except Exception as e:
        print(f"HATA: SonuÃ§lar dosyaya yazÄ±lÄ±rken hata oluÅŸtu: {e}")
        # Hata durumunda eski txt formatÄ±na geri dÃ¶n
        try:
            with open(file_path.replace('.docx', '.txt'), 'w', encoding='utf-8') as f:
                f.write('MÃœLAKAT ANALÄ°ZÄ° SONUCU\n')
                f.write('=' * 50 + '\n\n')
                
                f.write('1. ADAY DEÄERLENDÄ°RME PUANLAMA TABLOSU\n')
                f.write('-' * 45 + '\n')
                f.write(analysis_scoring + '\n\n')
                
                f.write('2. RECRUITER NOTU\n')
                f.write('-' * 17 + '\n')
                f.write(analysis_recruiter + '\n\n')
                
                f.write('3. GÃ–RÃœNTÃœ TABANLI KARAKTER ANALÄ°ZÄ°\n')
                f.write('-' * 35 + '\n')
                if image_analysis:
                    f.write(image_analysis + '\n\n')
                else:
                    f.write(f"{candidate_name} iÃ§in gÃ¶rÃ¼ntÃ¼ tabanlÄ± analiz yapÄ±lamadÄ±.\n\n")
                
                if analysis_qa:
                    f.write('4. SORU-CEVAP ANALÄ°ZÄ°\n')
                    f.write('-' * 22 + '\n')
                    f.write(analysis_qa + '\n\n')
                
                if analysis_technical:
                    f.write('5. TEKNÄ°K YETKÄ°NLÄ°K DEÄERLENDÄ°RMESÄ°\n')
                    f.write('-' * 37 + '\n')
                    f.write(analysis_technical + '\n\n')
                
                if analysis_soft_skills:
                    f.write('6. SOFT SKILL ANALÄ°ZÄ°\n')
                    f.write('-' * 22 + '\n')
                    f.write(analysis_soft_skills + '\n')
                    
            print(f"\nYedek olarak TXT formatÄ±nda kaydedildi.")
        except Exception as txt_error:
            print(f"HATA: TXT formatÄ±nda da kayÄ±t yapÄ±lamadÄ±: {txt_error}")

def adim_2_metin_analizi_yap(transcript_file_path, candidate_name="Aday"):
    """
    ADIM 2: Transkripti DOCX dosyasÄ±ndan okur, LLM'e analiz iÃ§in gÃ¶nderir ve sonuÃ§larÄ± dÃ¶ndÃ¼rÃ¼r.
    """
    print(f"--- ADIM 2: '{transcript_file_path}' DosyasÄ±ndaki Metin Analiz Ediliyor ---")

    interview_text = read_text_from_docx(transcript_file_path)
    if not interview_text or not interview_text.strip():
        print(f"HATA: '{transcript_file_path}' dosyasÄ± bulunamadÄ±, bozuk veya boÅŸ. Analiz yapÄ±lamÄ±yor.")
        return None, None

    print("MÃ¼lakat transkripti baÅŸarÄ±yla okundu.")

    print(f"'{MODEL_NAME}' modeline 'Aday DeÄŸerlendirme Puanlama Tablosu' iÃ§in istek gÃ¶nderiliyor...")
    prompt_scoring = PROMPT_SCORING_DETAILS.format(candidate_name=candidate_name)
    prompt_scoring = f"""
    AÅŸaÄŸÄ±daki mÃ¼lakat metnini profesyonel bir Ä°nsan KaynaklarÄ± (Ä°K) uzmanÄ± gibi analiz et. 
    Analizinin tamamÄ±nÄ±, mÃ¼lakat metninin dili ne olursa olsun, mutlaka TÃ¼rkÃ§e olarak oluÅŸtur.
    Analizini sadece aÅŸaÄŸÄ±daki baÅŸlÄ±k altÄ±nda yapÄ±landÄ±r ve detaylandÄ±r:
    {prompt_scoring}

    --- MÃœLAKAT METNÄ° ---
    {interview_text}
    --- ANALÄ°ZÄ°NÄ° BURAYA BAÅLAT ---
    """
    analysis_scoring = get_llm_analysis(prompt_scoring, MODEL_NAME)
    if not analysis_scoring:
        print("Puanlama analizi alÄ±namadÄ±. Ä°ÅŸlem durduruluyor.")
        return None, None
    print("Puanlama analizi baÅŸarÄ±yla tamamlandÄ±.")

    print(f"'{MODEL_NAME}' modeline 'Recruiter Notu' iÃ§in istek gÃ¶nderiliyor...")
    prompt_recruiter = PROMPT_RECRUITER_DETAILS.format(candidate_name=candidate_name)
    prompt_recruiter = f"""
    AÅŸaÄŸÄ±daki mÃ¼lakat Ã¶zetini profesyonel bir Ä°nsan KaynaklarÄ± (Ä°K) uzmanÄ± gibi analiz et.
    Analizinin tamamÄ±nÄ±, mÃ¼lakat metninin dili ne olursa olsun, mutlaka TÃ¼rkÃ§e olarak oluÅŸtur.
    Analizini sadece aÅŸaÄŸÄ±daki baÅŸlÄ±k altÄ±nda yapÄ±landÄ±r ve detaylandÄ±r:
    {prompt_recruiter}

    --- MÃœLAKAT METNÄ° ---
    {interview_text}
    --- ANALÄ°ZÄ°NÄ° BURAYA BAÅLAT ---
    """
    analysis_recruiter = get_llm_analysis(prompt_recruiter, MODEL_NAME)
    if not analysis_recruiter:
        print("Recruiter notu analizi alÄ±namadÄ±. Ä°ÅŸlem durduruluyor.")
        return None, None
    print("Recruiter notu analizi baÅŸarÄ±yla tamamlandÄ±.")

    return analysis_scoring, analysis_recruiter

def adim_2_metin_analizi_chunk(transcript_file_path, candidate_name="Aday"):
    """
    ADIM 2 (Chunk TabanlÄ±): Transkripti DOCX dosyasÄ±ndan okur, metni parÃ§alara bÃ¶ler,
    her parÃ§a iÃ§in Ã¶zet oluÅŸturur, Ã¶zetleri birleÅŸtirir ve tek bir nihai analiz yapar.
    """
    print(f"--- ADIM 2 (Chunk TabanlÄ±): '{transcript_file_path}' DosyasÄ±ndaki Metin Analiz Ediliyor ---")

    interview_text = read_text_from_docx(transcript_file_path)
    if not interview_text or not interview_text.strip():
        print(f"HATA: '{transcript_file_path}' dosyasÄ± bulunamadÄ±, bozuk veya boÅŸ. Analiz yapÄ±lamÄ±yor.")
        return None, None

    print("MÃ¼lakat transkripti baÅŸarÄ±yla okundu.")

    print("Metin parÃ§alara ayrÄ±lÄ±yor...")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=4000,
        chunk_overlap=200,
        length_function=len
    )
    chunks = text_splitter.split_text(interview_text)
    print(f"Metin {len(chunks)} parÃ§aya bÃ¶lÃ¼ndÃ¼.")

    chunk_summaries = []
    print("Her bir metin parÃ§asÄ± iÃ§in Ã¶zetler oluÅŸturuluyor...")
    for i, chunk in enumerate(chunks):
        print(f"ParÃ§a {i + 1}/{len(chunks)} iÅŸleniyor...")
        prompt_chunk_summary = f"""
        AÅŸaÄŸÄ±daki mÃ¼lakat metni parÃ§asÄ±nÄ± oku. Bu parÃ§adan, adayÄ±n aÅŸaÄŸÄ±da listelenen yetkinlikleri ile ilgili
        tÃ¼m Ã¶nemli bilgileri, kilit ifadeleri ve somut Ã¶rnekleri TÃ¼rkÃ§e olarak maddeler halinde Ã¶zetle.
        Sadece bu metin parÃ§asÄ±nda geÃ§en bilgileri kullan.

        Yetkinlikler:
        - Ä°letiÅŸim Becerisi
        - Motivasyon ve Tutku
        - KÃ¼ltÃ¼rel Uyum
        - Analitik/DÃ¼ÅŸÃ¼nsel Beceriler
        - Profesyonel Tutum
        - GeÃ§miÅŸ Deneyim Uyumu
        - Liderlik ve GiriÅŸimcilik
        - ZayÄ±flÄ±klarla BaÅŸa Ã‡Ä±kma Yetisi
        - Uzun Vadeli Potansiyel
        - Genel Etki / Ä°zlenim

        --- MÃœLAKAT METNÄ° PARÃ‡ASI ---
        {chunk}
        --- Ã–ZETÄ°NÄ° BURAYA BAÅLAT ---
        """
        summary = get_llm_analysis(prompt_chunk_summary, MODEL_NAME)
        if summary:
            chunk_summaries.append(summary)
        else:
            print(f"ParÃ§a {i + 1} iÃ§in Ã¶zet alÄ±namadÄ±. Ä°ÅŸlem durduruluyor.")
            return None, None

    combined_summary = "\n\n---\n\n".join(chunk_summaries)
    print("\nTÃ¼m parÃ§alarÄ±n Ã¶zetleri baÅŸarÄ±yla birleÅŸtirildi. Nihai analiz baÅŸlÄ±yor.")

    print("Nihai 'Aday DeÄŸerlendirme Puanlama Tablosu' oluÅŸturuluyor...")
    prompt_scoring = PROMPT_SCORING_DETAILS.format(candidate_name=candidate_name)
    prompt_scoring = f"""
    AÅŸaÄŸÄ±daki mÃ¼lakat Ã¶zetini profesyonel bir Ä°nsan KaynaklarÄ± (Ä°K) uzmanÄ± gibi analiz et.
    Analizinin tamamÄ±nÄ±, mÃ¼lakat metninin dili ne olursa olsun, mutlaka TÃ¼rkÃ§e olarak oluÅŸtur.
    Analizini sadece "1. Aday DeÄŸerlendirme Puanlama Tablosu" baÅŸlÄ±ÄŸÄ± altÄ±nda yapÄ±landÄ±r ve detaylandÄ±r:
    {prompt_scoring}

    --- MÃœLAKAT Ã–ZETÄ° METNÄ° ---
    {combined_summary}
    --- ANALÄ°ZÄ°NÄ° BURAYA BAÅLAT ---
    """
    analysis_scoring = get_llm_analysis(prompt_scoring, MODEL_NAME)
    if not analysis_scoring:
        print("Puanlama tablosu analizi oluÅŸturulamadÄ±. Ä°ÅŸlem durduruluyor.")
        return None, None

    print("Nihai 'Recruiter Notu' oluÅŸturuluyor...")
    prompt_recruiter = PROMPT_RECRUITER_DETAILS.format(candidate_name=candidate_name)
    prompt_recruiter = f"""
    AÅŸaÄŸÄ±daki mÃ¼lakat Ã¶zetini profesyonel bir Ä°nsan KaynaklarÄ± (Ä°K) uzmanÄ± gibi analiz et.
    Analizinin tamamÄ±nÄ±, mÃ¼lakat metninin dili ne olursa olsun, mutlaka TÃ¼rkÃ§e olarak oluÅŸtur.
    Analizini sadece "2. Recruiter Notu" baÅŸlÄ±ÄŸÄ± altÄ±nda yapÄ±landÄ±r ve detaylandÄ±r:
    {prompt_recruiter}

    --- MÃœLAKAT Ã–ZETÄ° METNÄ° ---
    {combined_summary}
    --- ANALÄ°ZÄ°NÄ° BURAYA BAÅLAT ---
    """
    analysis_recruiter = get_llm_analysis(prompt_recruiter, MODEL_NAME)
    if not analysis_recruiter:
        print("Recruiter notu analizi oluÅŸturulamadÄ±. Ä°ÅŸlem durduruluyor.")
        return None, None

    return analysis_scoring, analysis_recruiter

def advanced_content_analysis(transcript_file_path, candidate_name="Aday"):
    """
    GeliÅŸmiÅŸ iÃ§erik analizi: Q&A Matching, Technical Competency, Soft Skills
    """
    print(f"--- GELÄ°ÅMÄ°Å Ä°Ã‡ERÄ°K ANALÄ°ZÄ°: '{transcript_file_path}' DosyasÄ± Analiz Ediliyor ---")
    
    interview_text = read_text_from_docx(transcript_file_path)
    if not interview_text or not interview_text.strip():
        print(f"HATA: '{transcript_file_path}' dosyasÄ± bulunamadÄ±, bozuk veya boÅŸ. GeliÅŸmiÅŸ analiz yapÄ±lamÄ±yor.")
        return None, None, None
    
    print("MÃ¼lakat transkripti baÅŸarÄ±yla okundu. GeliÅŸmiÅŸ analizler baÅŸlÄ±yor...")
    
    # Q&A Matching Analizi
    print(f"'{MODEL_NAME}' modeline 'Soru-Cevap Analizi' iÃ§in istek gÃ¶nderiliyor...")
    prompt_qa = f"""
    AÅŸaÄŸÄ±daki mÃ¼lakat metnini profesyonel bir Ä°nsan KaynaklarÄ± (Ä°K) uzmanÄ± gibi analiz et.
    Analizinin tamamÄ±nÄ±, mÃ¼lakat metninin dili ne olursa olsun, mutlaka TÃ¼rkÃ§e olarak oluÅŸtur.
    Analizini sadece aÅŸaÄŸÄ±daki baÅŸlÄ±k altÄ±nda yapÄ±landÄ±r ve detaylandÄ±r:
    {PROMPT_QA_MATCHING}
    
    --- MÃœLAKAT METNÄ° ---
    {interview_text}
    --- ANALÄ°ZÄ°NÄ° BURAYA BAÅLAT ---
    """
    analysis_qa = get_llm_analysis(prompt_qa, MODEL_NAME)
    if not analysis_qa:
        print("Soru-Cevap analizi alÄ±namadÄ±.")
        analysis_qa = "Soru-Cevap analizi yapÄ±lamadÄ±."
    else:
        print("Soru-Cevap analizi baÅŸarÄ±yla tamamlandÄ±.")
    
    # Technical Competency Analizi
    print(f"'{MODEL_NAME}' modeline 'Teknik Yetkinlik DeÄŸerlendirmesi' iÃ§in istek gÃ¶nderiliyor...")
    prompt_tech = f"""
    AÅŸaÄŸÄ±daki mÃ¼lakat metnini profesyonel bir Ä°nsan KaynaklarÄ± (Ä°K) uzmanÄ± gibi analiz et.
    Analizinin tamamÄ±nÄ±, mÃ¼lakat metninin dili ne olursa olsun, mutlaka TÃ¼rkÃ§e olarak oluÅŸtur.
    Analizini sadece aÅŸaÄŸÄ±daki baÅŸlÄ±k altÄ±nda yapÄ±landÄ±r ve detaylandÄ±r:
    {PROMPT_TECHNICAL_COMPETENCY}
    
    --- MÃœLAKAT METNÄ° ---
    {interview_text}
    --- ANALÄ°ZÄ°NÄ° BURAYA BAÅLAT ---
    """
    analysis_technical = get_llm_analysis(prompt_tech, MODEL_NAME)
    if not analysis_technical:
        print("Teknik Yetkinlik analizi alÄ±namadÄ±.")
        analysis_technical = "Teknik Yetkinlik analizi yapÄ±lamadÄ±."
    else:
        print("Teknik Yetkinlik analizi baÅŸarÄ±yla tamamlandÄ±.")
    
    # Soft Skills Analizi
    print(f"'{MODEL_NAME}' modeline 'Soft Skill Analizi' iÃ§in istek gÃ¶nderiliyor...")
    prompt_soft = f"""
    AÅŸaÄŸÄ±daki mÃ¼lakat metnini profesyonel bir Ä°nsan KaynaklarÄ± (Ä°K) uzmanÄ± gibi analiz et.
    Analizinin tamamÄ±nÄ±, mÃ¼lakat metninin dili ne olursa olsun, mutlaka TÃ¼rkÃ§e olarak oluÅŸtur.
    Analizini sadece aÅŸaÄŸÄ±daki baÅŸlÄ±k altÄ±nda yapÄ±landÄ±r ve detaylandÄ±r:
    {PROMPT_SOFT_SKILLS}
    
    --- MÃœLAKAT METNÄ° ---
    {interview_text}
    --- ANALÄ°ZÄ°NÄ° BURAYA BAÅLAT ---
    """
    analysis_soft_skills = get_llm_analysis(prompt_soft, MODEL_NAME)
    if not analysis_soft_skills:
        print("Soft Skill analizi alÄ±namadÄ±.")
        analysis_soft_skills = "Soft Skill analizi yapÄ±lamadÄ±."
    else:
        print("Soft Skill analizi baÅŸarÄ±yla tamamlandÄ±.")
    
    return analysis_qa, analysis_technical, analysis_soft_skills

def extract_questions(interview_text):
    """
    MÃ¼lakat metninden sorularÄ± Ã§Ä±karÄ±r
    """
    questions = []
    lines = interview_text.split('\n')
    
    for line in lines:
        line = line.strip()
        # Soru iÅŸaretli cÃ¼mleleri tespit et
        if '?' in line and len(line) > 10:
            # KonuÅŸmacÄ± bilgisini temizle
            if ']:' in line:
                question = line.split(']:')[-1].strip()
            else:
                question = line
            
            if question and question not in questions:
                questions.append(question)
    
    return questions

def categorize_question(question):
    """
    Soruyu kategorize eder: Teknik, DavranÄ±ÅŸsal, Genel
    """
    question_lower = question.lower()
    
    # Teknik sorular iÃ§in anahtar kelimeler
    technical_keywords = ['kod', 'programlama', 'teknoloji', 'yazÄ±lÄ±m', 'algoritma', 
                         'veri', 'database', 'api', 'framework', 'python', 'java',
                         'makine Ã¶ÄŸrenmesi', 'yapay zeka', 'ai', 'ml']
    
    # DavranÄ±ÅŸsal sorular iÃ§in anahtar kelimeler
    behavioral_keywords = ['deneyim', 'proje', 'takÄ±m', 'liderlik', 'Ã§atÄ±ÅŸma', 
                          'zorluk', 'baÅŸarÄ±', 'hata', 'Ã¶ÄŸrenme', 'geliÅŸim',
                          'motivasyon', 'hedef', 'Ã§alÄ±ÅŸma tarzÄ±']
    
    # Teknik kategori kontrolÃ¼
    for keyword in technical_keywords:
        if keyword in question_lower:
            return "Teknik"
    
    # DavranÄ±ÅŸsal kategori kontrolÃ¼
    for keyword in behavioral_keywords:
        if keyword in question_lower:
            return "DavranÄ±ÅŸsal"
    
    # VarsayÄ±lan olarak Genel
    return "Genel"

# ==============================================================================
# --- ANA AKIÅ FONKSÄ°YONLARI ---
# ==============================================================================

def adim_1_videodan_metne_cevir():
    """
    ADIM 1: Videodan sesi Ã§Ä±karÄ±r, ElevenLabs ile deÅŸifre eder, duygu analizi yapar ve sonucu DOCX'e kaydeder.
    """
    print("--- ADIM 1: MÃ¼lakat Videosu Metne Ã‡evriliyor ve Duygu Analizi YapÄ±lÄ±yor ---")

    # 1.1. Video dosyasÄ±nÄ±n varlÄ±ÄŸÄ±nÄ± kontrol et
    if not os.path.exists(INPUT_VIDEO_FILE):
        print(f"HATA: '{INPUT_VIDEO_FILE}' video dosyasÄ± bulunamadÄ±. LÃ¼tfen kontrol edin.")
        return None, None, None

    # 1.2. Videodan sesi Ã§Ä±kar ve sÃ¼reyi hesapla
    try:
        print(f"'{INPUT_VIDEO_FILE}' videosundan ses Ã§Ä±karÄ±lÄ±yor...")
        with VideoFileClip(INPUT_VIDEO_FILE) as video:
            video_duration_minutes = video.duration / 60
            video.audio.write_audiofile(TEMP_AUDIO_FILE)
        print(f"Ses baÅŸarÄ±yla '{TEMP_AUDIO_FILE}' olarak kaydedildi.")
        print(f"Video sÃ¼resi: {video_duration_minutes:.2f} dakika")
    except Exception as e:
        print(f"HATA: Video iÅŸlenirken bir hata oluÅŸtu: {e}")
        return None, None, None

    # 1.3. ElevenLabs ile sesi yazÄ±ya Ã§evir
    words_data = []
    try:
        print(f"'{TEMP_AUDIO_FILE}' dosyasÄ± ElevenLabs API'sine gÃ¶nderiliyor (diarize=True)...")
        elevenlabs_client = ElevenLabs(api_key=ELEVENLABS_API_KEY)
        with open(TEMP_AUDIO_FILE, "rb") as audio_file:
            response = elevenlabs_client.speech_to_text.convert(
                file=audio_file,
                model_id="scribe_v1",
                diarize=True,
            )
            words_data = response.words
        print("Ses, ElevenLabs tarafÄ±ndan baÅŸarÄ±yla deÅŸifre edildi.")
    except Exception as e:
        print(f"HATA: ElevenLabs STT iÅŸlemi sÄ±rasÄ±nda hata: {e}")
        return None, None, None
    finally:
        if os.path.exists(TEMP_AUDIO_FILE):
            os.remove(TEMP_AUDIO_FILE)
            print(f"GeÃ§ici ses dosyasÄ± '{TEMP_AUDIO_FILE}' silindi.")

    # 1.4. Videodan duygu analizi yap
    duygu_cizelgesi = videodaki_duygulari_analiz_et(INPUT_VIDEO_FILE, SANIYEDE_ANALIZ_SAYISI)
    if not duygu_cizelgesi:
        print("UyarÄ±: Duygu analizi yapÄ±lamadÄ±. Transkript duygu bilgisi olmadan devam edecek.")

    # 1.5. Metni konuÅŸmacÄ±lara gÃ¶re ayÄ±r ve duygu bilgisi ekle
    if not words_data:
        print("HATA: ElevenLabs'tan kelime bazlÄ± veri alÄ±namadÄ±. Ä°ÅŸlem durduruluyor.")
        return None, None, None

    diarized_output = konusmacilari_ayir_ve_cumlele(words_data, duygu_cizelgesi)
    if not diarized_output:
        print("HATA: KonuÅŸmacÄ± ayrÄ±mÄ± yapÄ±lamadÄ± veya boÅŸ sonuÃ§ dÃ¶ndÃ¼.")
        return None, None, None

    # 1.6. Sonucu Word dosyasÄ±na yaz
    try:
        doc = Document()
        doc.add_heading('MÃ¼lakat Transkripti', level=1)
        for entry in diarized_output:
            start_min = int(entry['baslangic'] // 60)
            start_sec = int(entry['baslangic'] % 60)
            line = f"[{entry['konusmaci']}][{start_min}:{start_sec:02d}][{entry['duygu']}]: {entry['diyalog']}"
            doc.add_paragraph(line)
        doc.save(TRANSCRIPT_DOCX_FILE)
        print(f"Transkript baÅŸarÄ±yla '{TRANSCRIPT_DOCX_FILE}' dosyasÄ±na kaydedildi.")
        print("--- ADIM 1 TAMAMLANDI ---\n")
        return TRANSCRIPT_DOCX_FILE, video_duration_minutes, duygu_cizelgesi
    except Exception as e:
        print(f"HATA: Transkript Word dosyasÄ±na yazÄ±lÄ±rken hata oluÅŸtu: {e}")
        return None, None, None

# ==============================================================================
# --- BETÄ°ÄÄ° Ã‡ALIÅTIR ---
# ==============================================================================

if __name__ == "__main__":
    print("ğŸ¯ ===== GELÄ°ÅMÄ°Å MÃœLAKAT VÄ°DEOSU ANALÄ°Z SÃœRECÄ° BAÅLATILDI =====")
    print("ğŸ”§ Yeni Ã–zellikler: GeliÅŸmiÅŸ YÃ¼z Tespiti | AkÄ±llÄ± GÃ¶rsel Analiz | Video Kalite KontrolÃ¼")
    print("="*80)

    # AdÄ±m 0: Video kalitesi Ã¶n deÄŸerlendirmesi
    print("\nğŸ“‹ ADIM 0: Video Kalitesi Ã–n DeÄŸerlendirmesi")
    video_quality = assess_video_quality(INPUT_VIDEO_FILE)
    
    if video_quality['overall_score'] < 50:
        print(f"âš ï¸ UYARI: Video kalitesi dÃ¼ÅŸÃ¼k ({video_quality['overall_score']}/100)")
        print("âŒ Tespit edilen sorunlar:")
        for issue in video_quality.get('issues', []):
            print(f"   â€¢ {issue}")
        print("ğŸ’¡ Ã–neriler:")
        for rec in video_quality.get('recommendations', []):
            print(f"   â€¢ {rec}")
        
        user_choice = input("\nâ“ DÃ¼ÅŸÃ¼k kaliteli video ile devam etmek istiyor musunuz? (e/h): ").lower()
        if user_choice != 'e':
            print("ğŸ›‘ Ä°ÅŸlem kullanÄ±cÄ± tarafÄ±ndan durduruldu.")
            exit(1)
    else:
        print(f"âœ… Video kalitesi: {video_quality['quality_level']} ({video_quality['overall_score']}/100)")

    # AdÄ±m 1: Videodan transkript ve geliÅŸmiÅŸ duygu analizi
    print("\nğŸ“‹ ADIM 1: Video Ä°ÅŸleme ve GeliÅŸmiÅŸ Duygu Analizi")
    transcript_file, video_duration, duygu_cizelgesi = adim_1_videodan_metne_cevir()

    if transcript_file and video_duration is not None:
        # AdÄ±m 2: Transkriptten adayÄ±n ismini Ã§Ä±kar
        print("\nğŸ“‹ ADIM 2: Aday Ä°smi Tespiti")
        candidate_name = extract_candidate_name_from_text(transcript_file)
        if not candidate_name:
            candidate_name = "Aday"
            print("âš ï¸ UyarÄ±: Metinden isim tespit edilemedi, varsayÄ±lan isim 'Aday' kullanÄ±lacak.")
        else:
            print(f"âœ… Aday ismi tespit edildi: {candidate_name}")

        # AdÄ±m 3: GeliÅŸmiÅŸ yÃ¼z tespiti ve gÃ¶rÃ¼ntÃ¼ Ã§Ä±karma
        print("\nğŸ“‹ ADIM 3: GeliÅŸmiÅŸ YÃ¼z Tespiti ve GÃ¶rÃ¼ntÃ¼ Ã‡Ä±karma")
        final_name, face_image_path = extract_frame_and_name(INPUT_VIDEO_FILE, candidate_name, max_duration=60.0)

        # AdÄ±m 4: KapsamlÄ± gÃ¶rÃ¼ntÃ¼ tabanlÄ± karakter analizi
        print("\nğŸ“‹ ADIM 4: KapsamlÄ± GÃ¶rÃ¼ntÃ¼ TabanlÄ± Karakter Analizi")
        image_analysis = None
        image_quality_report = None
        
        if face_image_path and final_name == candidate_name:
            # Ã‡Ä±karÄ±lan gÃ¶rÃ¼ntÃ¼nÃ¼n kalitesini deÄŸerlendir
            image_quality_report = assess_image_quality(face_image_path)
            print(f"ğŸ“Š Ã‡Ä±karÄ±lan gÃ¶rÃ¼ntÃ¼ kalitesi: {image_quality_report['quality_level']} ({image_quality_report['score']}/100)")
            
            if image_quality_report['score'] >= 60:
                image_analysis = analyze_character_from_image(face_image_path)
                print("âœ… GeliÅŸmiÅŸ gÃ¶rÃ¼ntÃ¼ tabanlÄ± karakter analizi tamamlandÄ±.")
            else:
                print(f"âš ï¸ GÃ¶rÃ¼ntÃ¼ kalitesi dÃ¼ÅŸÃ¼k ({image_quality_report['score']}/100), analiz atlanÄ±yor.")
                print("âŒ Tespit edilen sorunlar:", ", ".join(image_quality_report.get('issues', [])))
        else:
            print(f"âŒ {candidate_name} iÃ§in uygun yÃ¼z gÃ¶rÃ¼ntÃ¼sÃ¼ bulunamadÄ±, gÃ¶rÃ¼ntÃ¼ analizi atlanÄ±yor.")

        # AdÄ±m 5: Metin tabanlÄ± analiz
        print("\nğŸ“‹ ADIM 5: Metin TabanlÄ± Analiz")
        if video_duration > DURATION_THRESHOLD:
            print(f"ğŸ“Š Video sÃ¼resi {video_duration:.2f} dakika, chunk tabanlÄ± analiz kullanÄ±lÄ±yor.")
            analysis_scoring, analysis_recruiter = adim_2_metin_analizi_chunk(transcript_file, candidate_name)
        else:
            print(f"ğŸ“Š Video sÃ¼resi {video_duration:.2f} dakika, standart analiz kullanÄ±lÄ±yor.")
            analysis_scoring, analysis_recruiter = adim_2_metin_analizi_yap(transcript_file, candidate_name)

        # AdÄ±m 6: GeliÅŸmiÅŸ iÃ§erik analizi
        print("\nğŸ“‹ ADIM 6: GeliÅŸmiÅŸ Ä°Ã§erik Analizi")
        analysis_qa, analysis_technical, analysis_soft_skills = advanced_content_analysis(transcript_file, candidate_name)

        # AdÄ±m 7: KapsamlÄ± rapor oluÅŸturma
        print("\nğŸ“‹ ADIM 7: KapsamlÄ± Analiz Raporu OluÅŸturma")
        if analysis_scoring and analysis_recruiter:
            # GÃ¶rsel analiz raporunu zenginleÅŸtir
            if image_analysis and image_quality_report:
                enhanced_image_analysis = f"""
{image_analysis}

ğŸ“Š GÃ–RÃœNTÃœ KALÄ°TE RAPORU
{"="*40}
Genel Kalite Skoru: {image_quality_report['score']}/100 ({image_quality_report['quality_level']})
Ã‡Ã¶zÃ¼nÃ¼rlÃ¼k: {image_quality_report['dimensions']}
Ã‡Ã¶zÃ¼nÃ¼rlÃ¼k Skoru: {image_quality_report['resolution_score']}/100
ParlaklÄ±k Skoru: {image_quality_report['brightness_score']}/100
Keskinlik Skoru: {image_quality_report['sharpness_score']}/100

ğŸ“¹ VÄ°DEO KALÄ°TE RAPORU
{"="*40}
Genel Video Kalitesi: {video_quality['overall_score']}/100 ({video_quality['quality_level']})
Ã‡Ã¶zÃ¼nÃ¼rlÃ¼k: {video_quality['video_info']['resolution']}
FPS: {video_quality['video_info']['fps']:.1f}
SÃ¼re: {video_quality['video_info']['duration']:.1f} saniye
"""
            else:
                enhanced_image_analysis = image_analysis
            
            write_analysis_to_txt(
                FINAL_ANALYSIS_TXT_FILE, 
                analysis_scoring, 
                analysis_recruiter, 
                enhanced_image_analysis, 
                candidate_name, 
                analysis_qa, 
                analysis_technical, 
                analysis_soft_skills
            )
            
            print(f"âœ… KapsamlÄ± analiz raporu '{FINAL_ANALYSIS_TXT_FILE}' dosyasÄ±na kaydedildi.")
        else:
            print("âŒ Metin analizi tamamlanamadÄ±, rapor oluÅŸturulamadÄ±.")
    else:
        print("\nâŒ SÃ¼reÃ§, video iÅŸleme aÅŸamasÄ±ndaki bir hata nedeniyle durduruldu.")

    # GeÃ§ici dosyalarÄ± temizle
    print("\nğŸ§¹ GeÃ§ici Dosyalar Temizleniyor...")
    for temp_file in [TEMP_FRAME_FILE, TEMP_FACE_FILE]:
        if os.path.exists(temp_file):
            os.remove(temp_file)
            print(f"ğŸ—‘ï¸ GeÃ§ici dosya '{temp_file}' silindi.")

    print("\nğŸ‰ ===== GELÄ°ÅMÄ°Å ANALÄ°Z SÃœRECÄ° BAÅARIYLA TAMAMLANDI =====")
    print("ğŸ“Š Analiz Ã–zeti:")
    print(f"   â€¢ Video Kalitesi: {video_quality.get('quality_level', 'Bilinmiyor')}")
    print(f"   â€¢ GÃ¶rsel Analiz: {'âœ… TamamlandÄ±' if image_analysis else 'âŒ AtlandÄ±'}")
    print(f"   â€¢ Duygu Analizi: {'âœ… TamamlandÄ±' if duygu_cizelgesi else 'âŒ AtlandÄ±'}")
    print(f"   â€¢ Metin Analizi: {'âœ… TamamlandÄ±' if analysis_scoring else 'âŒ BaÅŸarÄ±sÄ±z'}")
    print("ğŸ¯ GeliÅŸmiÅŸ IIAS sistemi ile analiz tamamlandÄ±!")